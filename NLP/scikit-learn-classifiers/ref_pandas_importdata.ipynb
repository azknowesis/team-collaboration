{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import numpy as np\n",
    "#filename = 'CMS32_DESC_LONG_DX_subset.txt'\n",
    "#data = np.loadtxt(filename, delimiter='|', dtype=str)\n",
    "#data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import csv\n",
    "#file = open(\"unisex_names_table.csv\")\n",
    "#csvreader = csv.reader(file)\n",
    "#airline_safety = list(csvreader)\n",
    "#print(airline_safety)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Pandas Selections and Indexing ](http://104.236.88.249/wp-content/uploads/2016/10/Pandas-selections-and-indexing.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Single selections using iloc and DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Single selections using iloc and DataFrame\n",
    "\n",
    "# Rows:\n",
    "\n",
    "data.iloc[0] # first row of data frame (Aleshia Tomkiewicz) - Note a Series data type output.\n",
    "\n",
    "data.iloc[1] # second row of data frame (Evan Zigomalas)\n",
    "\n",
    "data.iloc[-1] # last row of data frame (Mi Richan)\n",
    "\n",
    "# Columns:\n",
    "\n",
    "data.iloc[:,0] # first column of data frame (first_name)\n",
    "\n",
    "data.iloc[:,1] # second column of data frame (last_name)\n",
    "\n",
    "data.iloc[:,-1] # last column of data frame (id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple columns and rows can be selected together using the .iloc indexer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple row and column selections using iloc and DataFrame\n",
    "\n",
    "data.iloc[0:5] # first five rows of dataframe\n",
    "\n",
    "data.iloc[:, 0:2] # first two columns of data frame with all rows\n",
    "\n",
    "data.iloc[[0,3,6,24], [0,5,6]] # 1st, 4th, 7th, 25th row + 1st 6th 7th columns.\n",
    "\n",
    "data.iloc[0:5, 5:8] # first 5 rows and 5th, 6th, 7th columns of data frame (county -> phone1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> l2 = [1, 2, 3]\n",
    ">>> l1 = [4, 5, 6]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#l4=[]\n",
    "l4=l4+l2\n",
    "l4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use names parameter\n",
    "df = pd.read_csv(file_path, usecols=[3,6], names=['colA', 'colB'])\n",
    "or use header=None to explicitly tells people that the csv has no headers (anyway both lines are identical)\n",
    "df = pd.read_csv(file_path, usecols=[3,6], names=['colA', 'colB'], header=None)\n",
    "So that you can retrieve your data by \n",
    "### with `names` parameter\n",
    "df['colA']\n",
    "df['colB'] \n",
    "instead of \n",
    "### without `names` parameter\n",
    "df[0]\n",
    "df[1]\n",
    "### Use nrows parameter\n",
    "to import top 50 rows: nrows=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 2)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "filename = '~/Documents/NLP/CMS32_DESC_LONG_DX_subset.txt'\n",
    "df = pd.read_csv(filename, header=None, delimiter='|', dtype=str, nrows=100)\n",
    "df.shape\n",
    "#print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0                                                  1\n",
      "67  36300                 Focal chorioretinitis, unspecified\n",
      "68  36301  Focal choroiditis and chorioretinitis, juxtapa...\n",
      "69  36303  Focal choroiditis and chorioretinitis of other...\n",
      "70  36304  Focal choroiditis and chorioretinitis, peripheral\n",
      "71  36305  Focal retinitis and retinochoroiditis, juxtapa...\n",
      "72  36306  Focal retinitis and retinochoroiditis, macular...\n",
      "73  36307  Focal retinitis and retinochoroiditis of other...\n",
      "74  36308  Focal retinitis and retinochoroiditis, peripheral\n",
      "75  36310          Disseminated chorioretinitis, unspecified\n",
      "76  36311  Disseminated choroiditis and chorioretinitis, ...\n",
      "77  36312  Disseminated choroiditis and chorioretinitis, ...\n",
      "78  36313  Disseminated choroiditis and chorioretinitis, ...\n",
      "79  36314  Disseminated retinitis and retinochoroiditis, ...\n",
      "80  36315  Disseminated retinitis and retinochoroiditis, ...\n",
      "81  36320                       Chorioretinitis, unspecified\n",
      "82  36321                                      Pars planitis\n",
      "83  36322                                   Harada's disease\n",
      "84  36330                    Chorioretinal scar, unspecified\n",
      "85  36331                                  Solar retinopathy\n",
      "86  36332                                Other macular scars\n",
      "87  36333                      Other scars of posterior pole\n",
      "88  36334                                   Peripheral scars\n",
      "89  36335                                 Disseminated scars\n",
      "90  36340                Choroidal degeneration, unspecified\n",
      "91  36341                          Senile atrophy of choroid\n",
      "92  36342               Diffuse secondary atrophy of choroid\n",
      "93  36343                         Angioid streaks of choroid\n",
      "94  36350  Hereditary choroidal dystrophy or atrophy, uns...\n",
      "95  36351      Circumpapillary dystrophy of choroid, partial\n",
      "96  36352        Circumpapillary dystrophy of choroid, total\n",
      "97  36353              Central dystrophy of choroid, partial\n",
      "98  36354                   Central choroidal atrophy, total\n",
      "99  36355                                      Choroideremia\n"
     ]
    }
   ],
   "source": [
    "df1 = df[df[0].str.contains(\"363\")]\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df1.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> from sklearn.feature_extraction.text import CountVectorizer\n",
    ">>> from sklearn.feature_extraction import stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None,\n",
       "        stop_words=frozenset({'hundred', 'therefore', 'their', 'un', 'thin', 'third', 'whence', 'an', 'hers', 'who', 'after', 'all', 'within', 'yourself', 'fifteen', 'perhaps', 'namely', 'than', 'noone', 'six', 'more', 'always', 'whither', 'due', 'amoungst', 'below', 'interest', 'why', 'even', 'call', 'else...im', 'wherein', 'out', 'done', 'wherever', 'well', 'sixty', 'we', 'many', 'those', 'she', 'itself'}),\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> vectorizer = CountVectorizer(stop_words=stop_words.ENGLISH_STOP_WORDS)\n",
    ">>> vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<33x42 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 114 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#>>> t,z = data[:,0], data[:,3] \n",
    ">>> corpus = df1[:,1]\n",
    ">>> X = vectorizer.fit_transform(corpus)\n",
    ">>> X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['angioid',\n",
       " 'atrophy',\n",
       " 'central',\n",
       " 'chorioretinal',\n",
       " 'chorioretinitis',\n",
       " 'choroid',\n",
       " 'choroidal',\n",
       " 'choroideremia',\n",
       " 'choroiditis',\n",
       " 'circumpapillary',\n",
       " 'degeneration',\n",
       " 'diffuse',\n",
       " 'disease',\n",
       " 'disseminated',\n",
       " 'dystrophy',\n",
       " 'epitheliopathy',\n",
       " 'focal',\n",
       " 'generalized',\n",
       " 'harada',\n",
       " 'hereditary',\n",
       " 'juxtapapillary',\n",
       " 'macular',\n",
       " 'metastatic',\n",
       " 'paramacular',\n",
       " 'pars',\n",
       " 'partial',\n",
       " 'peripheral',\n",
       " 'pigment',\n",
       " 'planitis',\n",
       " 'pole',\n",
       " 'posterior',\n",
       " 'retinitis',\n",
       " 'retinochoroiditis',\n",
       " 'retinopathy',\n",
       " 'scar',\n",
       " 'scars',\n",
       " 'secondary',\n",
       " 'senile',\n",
       " 'solar',\n",
       " 'streaks',\n",
       " 'total',\n",
       " 'unspecified']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 1, ..., 0, 0, 0],\n",
       "       [0, 1, 1, ..., 0, 1, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> X.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence words that were not seen in the training corpus will be completely ignored in future calls to the transform method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> vectorizer.transform(['Something completely diabetic.']).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As tf–idf is very often used for text features, there is also another class called TfidfVectorizer that combines all the options of CountVectorizer and TfidfTransformer in a single model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.80173655, 0.45973138, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.3819235 , 0.        , 0.        ],\n",
       "       [0.        , 0.41174171, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.84466947, 0.34205591, 0.        , 0.        ],\n",
       "       [0.        , 0.35947373, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.48761927, 0.73744407,\n",
       "        0.        , 0.2986341 , 0.        , 0.        ],\n",
       "       [0.        , 0.35947373, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.73744407, 0.        , 0.48761927, 0.        ,\n",
       "        0.        , 0.2986341 , 0.        , 0.        ],\n",
       "       [0.        , 0.35947373, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.73744407, 0.48761927, 0.        ,\n",
       "        0.        , 0.2986341 , 0.        , 0.        ],\n",
       "       [0.        , 0.35947373, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.48761927, 0.        ,\n",
       "        0.        , 0.2986341 , 0.73744407, 0.        ],\n",
       "       [0.        , 0.32587066, 0.6685089 , 0.        , 0.        ,\n",
       "        0.6685089 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.61889978, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.29482549, 0.        , 0.72803914],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.92688349,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.37534916, 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.92688349, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.37534916, 0.        , 0.        ]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> from sklearn.feature_extraction.text import TfidfVectorizer\n",
    ">>> vectorizer_t = TfidfVectorizer(stop_words=stop_words.ENGLISH_STOP_WORDS)\n",
    ">>> vectorizer_t.fit_transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> vectorizer_t.transform(['Something completely diabetic.']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
