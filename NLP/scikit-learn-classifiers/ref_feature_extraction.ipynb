{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### char_wb analyzer is used, which creates n-grams only from characters inside word boundaries (padded with space on each side). The char analyzer, alternatively, creates n-grams that span across words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "ngram_vectorizer = CountVectorizer(analyzer='char_wb', ngram_range=(5, 5))\n",
    "ngram_vectorizer.fit_transform(['jumpy fox'])\n",
    "                               \n",
    "\n",
    "\n",
    "ngram_vectorizer.get_feature_names() == (\n",
    "    [' fox ', ' jump', 'jumpy', 'umpy '])\n",
    "\n",
    "\n",
    "ngram_vectorizer = CountVectorizer(analyzer='char', ngram_range=(5, 5))\n",
    "ngram_vectorizer.fit_transform(['jumpy fox'])\n",
    "                               \n",
    "\n",
    "\n",
    "ngram_vectorizer.get_feature_names() == (\n",
    "    ['jumpy', 'mpy f', 'py fo', 'umpy ', 'y fox'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x5 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 5 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram_vectorizer = CountVectorizer(analyzer='word', ngram_range=(2, 2))\n",
    "ngram_vectorizer.fit_transform(['concussion with no loss of consciousness'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['concussion with', 'loss of', 'no loss', 'of consciousness', 'with no']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram_vectorizer.get_feature_names() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['concussion',\n",
       " 'concussion with',\n",
       " 'consciousness',\n",
       " 'loss',\n",
       " 'loss of',\n",
       " 'no',\n",
       " 'no loss',\n",
       " 'of',\n",
       " 'of consciousness',\n",
       " 'with',\n",
       " 'with no']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram_vectorizer = CountVectorizer(analyzer='word', ngram_range=(1, 2))\n",
    "cv_fit=ngram_vectorizer.fit_transform(['concussion with no loss of consciousness'])\n",
    "ngram_vectorizer.get_feature_names() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute a simple word frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Option 1: it is much faster to perform the sum on the sparse matrix and then transform it to an array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.asarray(cv_fit.sum(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Option 2: perform as array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(cv_fit.toarray().sum(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note that the dimensionality does not affect the CPU training time of algorithms which operate on CSR matrices (LinearSVC(dual=True), Perceptron, SGDClassifier, PassiveAggressive) but it does for algorithms that work with CSC matrices (LinearSVC(dual=False), Lasso(), etc)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.4.1. Patch extraction\n",
    "\n",
    "The extract_patches_2d function extracts patches from an image stored as a two-dimensional array, or three-dimensional with color information along the third axis. For rebuilding an image from all its patches, use reconstruct_from_patches_2d. For example let use generate a 4x4 pixel picture with 3 color channels (e.g. in RGB format):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  3,  6,  9],\n",
       "       [12, 15, 18, 21],\n",
       "       [24, 27, 30, 33],\n",
       "       [36, 39, 42, 45]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction import image\n",
    "\n",
    "one_image = np.arange(4 * 4 * 3).reshape((4, 4, 3))\n",
    "one_image[:, :, 0]  # R channel of a fake RGB picture\n",
    "\n",
    "\n",
    "\n",
    "patches = image.extract_patches_2d(one_image, (2, 2), max_patches=2,\n",
    "    random_state=0)\n",
    "patches.shape\n",
    "\n",
    "patches[:, :, :, 0]\n",
    "\n",
    "\n",
    "\n",
    "patches = image.extract_patches_2d(one_image, (2, 2))\n",
    "patches.shape\n",
    "\n",
    "patches[4, :, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
